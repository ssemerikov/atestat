#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–∞—Ä—Å–∏–Ω–≥ Excel —Ñ–∞–π–ª—É –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞—Ç–µ—Å—Ç–∞—Ü—ñ—ó –ó–í–û

–ê–≤—Ç–æ—Ä–∏: –ì–∞–º–∞–Ω—é–∫ –í—ñ—Ç–∞ –ê–Ω–∞—Ç–æ–ª—ñ—ó–≤–Ω–∞, –°. –û. –°–µ–º–µ—Ä—ñ–∫–æ–≤
–ó–∞—Å—ñ–± —Ä–æ–∑—Ä–æ–±–∫–∏: Claude Code
"""

import pandas as pd
import numpy as np
import json
import os
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import warnings

warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')


class AttestationDataParser:
    """–ö–ª–∞—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É —Ç–∞ –∫–æ–Ω—Å–æ–ª—ñ–¥–∞—Ü—ñ—ó –¥–∞–Ω–∏—Ö –∞—Ç–µ—Å—Ç–∞—Ü—ñ—ó –ó–í–û"""

    # –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏ –∑ –º–µ—Ç–æ–¥–∏–∫–∏ –∞—Ç–µ—Å—Ç–∞—Ü—ñ—ó
    TOTAL_KI = 54.0  # –ó–∞–≥–∞–ª—å–Ω–∞ —Å—É–º–∞ –≤–∞–≥–æ–≤–∏—Ö –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç—ñ–≤ –¥–ª—è –ó–í–û (35 —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤ –¥–ª—è –ù–£ = 52.5)

    # –í–∞–≥–æ–≤—ñ –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç–∏ –≤—Å—ñ—Ö 37 —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤ (–∑–≥—ñ–¥–Ω–æ –∑ –æ—Ñ—ñ—Ü—ñ–π–Ω–æ—é –º–µ—Ç–æ–¥–∏–∫–æ—é)
    INDICATORS_KI = {
        # –ë–ª–æ–∫ 1: –ö–∞–¥—Ä–æ–≤–∏–π –ø–æ—Ç–µ–Ω—Ü—ñ–∞–ª (6,5)
        'I1': 1.0, 'I2': 1.0, 'I3': 1.0, 'I4': 1.0, 'I5': 0.5, 'I6': 1.0,
        # –ë–ª–æ–∫ 2: –§—ñ–Ω–∞–Ω—Å–æ–≤–∞ –¥—ñ—è–ª—å–Ω—ñ—Å—Ç—å (13,5)
        'I7': 1.0, 'I8': 3.0, 'I9': 2.0, 'I10': 1.0, 'I11': 3.0, 'I12': 2.0, 'I13': 1.0, 'I14': 0.5,
        # –ë–ª–æ–∫ 3: –ü—É–±–ª—ñ–∫–∞—Ü—ñ–π–Ω–∞ –∞–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å (9,55)
        'I15': 1.5, 'I16': 1.2, 'I17': 1.0, 'I18': 1.0, 'I19': 1.5, 'I20': 0.75, 'I21': 0.35, 'I22': 0.5, 'I23': 0.2,
        # –ë–ª–æ–∫ 4: –Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞ –≤–ª–∞—Å–Ω—ñ—Å—Ç—å (13,5)
        'I24': 1.0, 'I25': 1.0, 'I26': 3.0, 'I27': 1.0, 'I28': 1.0, 'I29': 4.0, 'I30': 0.5, 'I31': 2.0,
        # –ë–ª–æ–∫ 5: –ö–æ–Ω–∫—É—Ä—Å–Ω–µ —Ñ—ñ–Ω–∞–Ω—Å—É–≤–∞–Ω–Ω—è (13,5)
        'I32': 4.0, 'I33': 1.0, 'I34': 2.0, 'I35': 0.5, 'I36': 2.0, 'I37': 4.0
    }

    # –ë–ª–æ–∫–∏ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤
    INDICATOR_BLOCKS = {
        '–ö–∞–¥—Ä–æ–≤–∏–π –ø–æ—Ç–µ–Ω—Ü—ñ–∞–ª': ['I1', 'I2', 'I3', 'I4', 'I5', 'I6'],
        '–§—ñ–Ω–∞–Ω—Å–æ–≤–∞ –¥—ñ—è–ª—å–Ω—ñ—Å—Ç—å': ['I7', 'I8', 'I9', 'I10', 'I11', 'I12', 'I13', 'I14'],
        '–ü—É–±–ª—ñ–∫–∞—Ü—ñ–π–Ω–∞ –∞–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å': ['I15', 'I16', 'I17', 'I18', 'I19', 'I20', 'I21', 'I22'],
        '–Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞ –≤–ª–∞—Å–Ω—ñ—Å—Ç—å': ['I23', 'I24', 'I25', 'I26', 'I27', 'I28', 'I29', 'I30', 'I31'],
        '–ö–æ–Ω–∫—É—Ä—Å–Ω–µ —Ñ—ñ–Ω–∞–Ω—Å—É–≤–∞–Ω–Ω—è': ['I32', 'I33', 'I34', 'I35', 'I36', 'I37']
    }

    # –ù–∞—É–∫–æ–≤—ñ –Ω–∞–ø—Ä—è–º–∏
    SCIENCE_DIRECTIONS = {
        1: '–ê–≥—Ä–∞—Ä–Ω–æ-–≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–∏–π',
        2: '–ì—É–º–∞–Ω—ñ—Ç–∞—Ä–Ω–æ-–º–∏—Å—Ç–µ—Ü—å–∫–∏–π',
        3: '–°—É—Å–ø—ñ–ª—å–Ω–∏–π',
        4: '–ë—ñ–æ–º–µ–¥–∏—á–Ω–∏–π',
        5: '–ü—Ä–∏—Ä–æ–¥–Ω–∏—á–æ-–º–∞—Ç–µ–º–∞—Ç–∏—á–Ω–∏–π',
        6: '–Ü–Ω–∂–µ–Ω–µ—Ä–Ω–æ-—Ç–µ—Ö–Ω–æ–ª–æ–≥—ñ—á–Ω–∏–π',
        7: '–ë–µ–∑–ø–µ–∫–æ–≤–∏–π'
    }

    # –ì—Ä—É–ø–∏ –∞—Ç–µ—Å—Ç–∞—Ü—ñ—ó
    ATTESTATION_GROUPS = {
        '–ê': {'min': 75, 'max': 100, 'description': '–ù–∞–π–≤–∏—â–∞ –æ—Ü—ñ–Ω–∫–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ'},
        '–ë': {'min': 50, 'max': 75, 'description': '–í–∏—Å–æ–∫–∞ –æ—Ü—ñ–Ω–∫–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ'},
        '–í': {'min': 25, 'max': 50, 'description': '–ó–∞–¥–æ–≤—ñ–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ'},
        '–ì': {'min': 0, 'max': 25, 'description': '–ù–ï –ü–†–û–ô–®–õ–ò –ê–¢–ï–°–¢–ê–¶–Ü–Æ'}
    }

    def __init__(self, excel_path: str):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–∞—Ä—Å–µ—Ä–∞

        Args:
            excel_path: –®–ª—è—Ö –¥–æ Excel —Ñ–∞–π–ª—É –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞—Ç–µ—Å—Ç–∞—Ü—ñ—ó
        """
        self.excel_path = Path(excel_path)
        if not self.excel_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {excel_path}")

        self.sheets = {}
        self.consolidated_data = None
        self.validation_results = {}

    def load_all_sheets(self) -> Dict[str, pd.DataFrame]:
        """
        –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤—Å—ñ—Ö –≤–∫–ª–∞–¥–æ–∫ Excel —Ñ–∞–π–ª—É

        Returns:
            –°–ª–æ–≤–Ω–∏–∫ –∑ –Ω–∞–∑–≤–∞–º–∏ –≤–∫–ª–∞–¥–æ–∫ —Ç–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–º–∏ DataFrame
        """
        print(f"üìÇ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è Excel —Ñ–∞–π–ª—É: {self.excel_path.name}")

        try:
            excel_file = pd.ExcelFile(self.excel_path, engine='openpyxl')
            sheet_names = excel_file.sheet_names

            print(f"üìä –ó–Ω–∞–π–¥–µ–Ω–æ {len(sheet_names)} –≤–∫–ª–∞–¥–æ–∫:")

            for sheet_name in sheet_names:
                df = pd.read_excel(excel_file, sheet_name=sheet_name)
                self.sheets[sheet_name] = df
                print(f"  ‚úì {sheet_name}: {df.shape[0]} —Ä—è–¥–∫—ñ–≤ √ó {df.shape[1]} —Å—Ç–æ–≤–ø—Ü—ñ–≤")

            return self.sheets

        except Exception as e:
            raise Exception(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ Excel —Ñ–∞–π–ª—É: {str(e)}")

    def _extract_indicator_columns(self, df_raw: pd.DataFrame) -> Dict[str, int]:
        """
        –í–∏—Ç—è–≥—É–≤–∞–Ω–Ω—è —ñ–Ω–¥–µ–∫—Å—ñ–≤ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ I1-I37
        –∑ —Ä—è–¥–∫–∞ 0 (row with indicator labels)

        Args:
            df_raw: –°–∏—Ä–∏–π DataFrame –∑ –≤–∫–ª–∞–¥–∫–∏ –î–æ–≤—ñ–¥–Ω–∏–∫–∏

        Returns:
            –°–ª–æ–≤–Ω–∏–∫ {indicator: column_index}, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥ {'I1': 17, 'I2': 20, ...}
        """
        import re

        indicator_columns = {}

        # –†—è–¥–æ–∫ 0 –º—ñ—Å—Ç–∏—Ç—å –ø–æ–∑–Ω–∞—á–∫–∏ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤
        header_row = df_raw.iloc[0]

        for col_idx, value in enumerate(header_row):
            if pd.notna(value):
                value_str = str(value).strip()
                # –®—É–∫–∞—î–º–æ –ø–∞—Ç–µ—Ä–Ω "I" followed by digits (–±–µ–∑ –∑—ñ—Ä–æ—á–∫–∏)
                match = re.match(r'^I(\d+)$', value_str)
                if match:
                    indicator_num = match.group(1)
                    indicator_name = f'I{indicator_num}'
                    indicator_columns[indicator_name] = col_idx

        return indicator_columns

    def parse_dovidnyky_sheet(self) -> Tuple[pd.DataFrame, Dict[str, int]]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –≤–∫–ª–∞–¥–∫–∏ '–î–æ–≤—ñ–¥–Ω–∏–∫–∏' –∑ –≤—Å—ñ–º–∞ –ø–æ–∫–∞–∑–Ω–∏–∫–∞–º–∏ P, R, F, I
        –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º —Ä–æ–∑–±–æ—Ä–æ–º –±–∞–≥–∞—Ç–æ—Ä—ñ–≤–Ω–µ–≤–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤

        Returns:
            Tuple –∑ DataFrame (–¥–∞–Ω—ñ, –ø—Ä–æ–ø—É—Å—Ç–∏–≤—à–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏) —Ç–∞ —Å–ª–æ–≤–Ω–∏–∫–æ–º —ñ–Ω–¥–µ–∫—Å—ñ–≤ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤
        """
        print("\nüìã –ü–∞—Ä—Å–∏–Ω–≥ –≤–∫–ª–∞–¥–∫–∏ '–î–æ–≤—ñ–¥–Ω–∏–∫–∏'...")

        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Å–∏—Ä—ñ –¥–∞–Ω—ñ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤
        df_raw = pd.read_excel(self.excel_path, sheet_name='–î–æ–≤—ñ–¥–Ω–∏–∫–∏', nrows=5, engine='openpyxl')

        # –í–∏—Ç—è–≥—É—î–º–æ —ñ–Ω–¥–µ–∫—Å–∏ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤
        indicator_columns = self._extract_indicator_columns(df_raw)

        print(f"  ‚úì –ó–Ω–∞–π–¥–µ–Ω–æ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤ I: {len(indicator_columns)}")

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –≤—Å—ñ—Ö 37 —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤
        expected_indicators = set(self.INDICATORS_KI.keys())
        found_indicators = set(indicator_columns.keys())
        missing_indicators = expected_indicators - found_indicators

        if missing_indicators:
            print(f"  ‚ö† –í—ñ–¥—Å—É—Ç–Ω—ñ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏: {sorted(missing_indicators)}")
        else:
            print(f"  ‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ –í–°–Ü 37 —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤!")

        # –¢–µ–ø–µ—Ä –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ä–µ–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ, –ø—Ä–æ–ø—É—Å–∫–∞—é—á–∏ –ø–µ—Ä—à—ñ 3 —Ä—è–¥–∫–∏ –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤
        df_data = pd.read_excel(self.excel_path, sheet_name='–î–æ–≤—ñ–¥–Ω–∏–∫–∏', skiprows=3, engine='openpyxl')

        print(f"  ‚úì –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(df_data)} –ó–í–û –∑ –¥–∞–Ω–∏–º–∏")

        return df_data, indicator_columns

    def parse_results_sheet(self, directions=['–°—É—Å–ø—ñ–ª—å–Ω–∏–π', '–ê–≥—Ä–∞—Ä–Ω–æ-–≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–∏–π']) -> pd.DataFrame:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –≤–∫–ª–∞–¥–∫–∏ '–†–µ–∑—É–ª—å—Ç–∞—Ç–∏' –∑ –ø—ñ–¥—Å—É–º–∫–æ–≤–∏–º–∏ –æ—Ü—ñ–Ω–∫–∞–º–∏

        Args:
            directions: –°–ø–∏—Å–æ–∫ –Ω–∞—É–∫–æ–≤–∏—Ö –Ω–∞–ø—Ä—è–º—ñ–≤ –¥–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó

        Returns:
            DataFrame –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞—Ç–µ—Å—Ç–∞—Ü—ñ—ó –¥–ª—è –∑–∞–∑–Ω–∞—á–µ–Ω–∏—Ö –Ω–∞–ø—Ä—è–º—ñ–≤
        """
        print("\nüìä –ü–∞—Ä—Å–∏–Ω–≥ –≤–∫–ª–∞–¥–∫–∏ '–†–µ–∑—É–ª—å—Ç–∞—Ç–∏'...")

        if '–†–µ–∑—É–ª—å—Ç–∞—Ç–∏' not in self.sheets:
            raise KeyError("–í–∫–ª–∞–¥–∫–∞ '–†–µ–∑—É–ª—å—Ç–∞—Ç–∏' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞")

        df = self.sheets['–†–µ–∑—É–ª—å—Ç–∞—Ç–∏'].copy()

        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ª–∏—à–µ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –Ω–∞–ø—Ä—è–º–∏
        if '–ù–∞–ø—Ä—è–º' in df.columns:
            df = df[df['–ù–∞–ø—Ä—è–º'].isin(directions)]
            print(f"  ‚úì –í—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(df)} –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è –Ω–∞–ø—Ä—è–º—ñ–≤: {', '.join(directions)}")
        else:
            print(f"  ‚ö† –ö–æ–ª–æ–Ω–∫–∞ '–ù–∞–ø—Ä—è–º' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞, –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –≤—Å—ñ {len(df)} –∑–∞–ø–∏—Å—ñ–≤")

        return df

    def parse_detali_sheet(self, directions=['–°—É—Å–ø—ñ–ª—å–Ω–∏–π', '–ê–≥—Ä–∞—Ä–Ω–æ-–≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–∏–π']) -> pd.DataFrame:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –≤–∫–ª–∞–¥–∫–∏ '–î–µ—Ç–∞–ª—ñ 3.0' –∑ –¥–µ—Ç–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏

        Args:
            directions: –°–ø–∏—Å–æ–∫ –Ω–∞—É–∫–æ–≤–∏—Ö –Ω–∞–ø—Ä—è–º—ñ–≤ –¥–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó

        Returns:
            DataFrame –∑ –¥–µ—Ç–∞–ª—è–º–∏ –ø–æ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞—Ö –¥–ª—è –∑–∞–∑–Ω–∞—á–µ–Ω–∏—Ö –Ω–∞–ø—Ä—è–º—ñ–≤
        """
        print("\nüîç –ü–∞—Ä—Å–∏–Ω–≥ –≤–∫–ª–∞–¥–∫–∏ '–î–µ—Ç–∞–ª—ñ 3.0'...")

        if '–î–µ—Ç–∞–ª—ñ 3.0' not in self.sheets:
            print("  ‚ö† –í–∫–ª–∞–¥–∫–∞ '–î–µ—Ç–∞–ª—ñ 3.0' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞")
            return None

        df = self.sheets['–î–µ—Ç–∞–ª—ñ 3.0'].copy()

        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ª–∏—à–µ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –Ω–∞–ø—Ä—è–º–∏
        if '–ù–∞–ø—Ä—è–º' in df.columns:
            df = df[df['–ù–∞–ø—Ä—è–º'].isin(directions)]
            print(f"  ‚úì –í—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(df)} –¥–µ—Ç–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è –Ω–∞–ø—Ä—è–º—ñ–≤: {', '.join(directions)}")
        else:
            print(f"  ‚ö† –ö–æ–ª–æ–Ω–∫–∞ '–ù–∞–ø—Ä—è–º' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞, –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –≤—Å—ñ {len(df)} –∑–∞–ø–∏—Å—ñ–≤")

        return df

    def parse_dynamika_sheet(self, directions=['–°—É—Å–ø—ñ–ª—å–Ω–∏–π', '–ê–≥—Ä–∞—Ä–Ω–æ-–≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–∏–π']) -> pd.DataFrame:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –≤–∫–ª–∞–¥–∫–∏ '–î–∏–Ω–∞–º—ñ–∫–∞' –∑ —á–∞—Å–æ–≤–∏–º–∏ —Ä—è–¥–∞–º–∏ 2019-2023

        Args:
            directions: –°–ø–∏—Å–æ–∫ –Ω–∞—É–∫–æ–≤–∏—Ö –Ω–∞–ø—Ä—è–º—ñ–≤ –¥–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó

        Returns:
            DataFrame –∑ –¥–∏–Ω–∞–º—ñ–∫–æ—é –ø–æ–∫–∞–∑–Ω–∏–∫—ñ–≤ –¥–ª—è –∑–∞–∑–Ω–∞—á–µ–Ω–∏—Ö –Ω–∞–ø—Ä—è–º—ñ–≤
        """
        print("\nüìà –ü–∞—Ä—Å–∏–Ω–≥ –≤–∫–ª–∞–¥–∫–∏ '–î–∏–Ω–∞–º—ñ–∫–∞'...")

        if '–î–∏–Ω–∞–º—ñ–∫–∞' not in self.sheets:
            print("  ‚ö† –í–∫–ª–∞–¥–∫–∞ '–î–∏–Ω–∞–º—ñ–∫–∞' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞")
            return None

        df = self.sheets['–î–∏–Ω–∞–º—ñ–∫–∞'].copy()

        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ª–∏—à–µ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –Ω–∞–ø—Ä—è–º–∏
        direction_col = '–ù–∞—É–∫–æ–≤–∏–π –Ω–∞–ø—Ä—è–º * –†—ñ–≤–µ–Ω—å 0'
        if direction_col in df.columns:
            df = df[df[direction_col].isin(directions)]
            print(f"  ‚úì –í—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(df)} –∑–∞–ø–∏—Å—ñ–≤ –¥–∏–Ω–∞–º—ñ–∫–∏ –¥–ª—è –Ω–∞–ø—Ä—è–º—ñ–≤: {', '.join(directions)}")
        else:
            print(f"  ‚ö† –ö–æ–ª–æ–Ω–∫–∞ '{direction_col}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞, –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –≤—Å—ñ {len(df)} –∑–∞–ø–∏—Å—ñ–≤")

        return df

    def parse_medians_sheet(self, directions=['–°—É—Å–ø—ñ–ª—å–Ω–∏–π', '–ê–≥—Ä–∞—Ä–Ω–æ-–≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–∏–π']) -> pd.DataFrame:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –≤–∫–ª–∞–¥–∫–∏ '–ú–∞–¥—ñ–∞–Ω–∏' –∑ –º–µ–¥—ñ–∞–Ω–∞–º–∏ –ø–æ–∫–∞–∑–Ω–∏–∫—ñ–≤

        Args:
            directions: –°–ø–∏—Å–æ–∫ –Ω–∞—É–∫–æ–≤–∏—Ö –Ω–∞–ø—Ä—è–º—ñ–≤ –¥–ª—è —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó

        Returns:
            DataFrame –∑ –º–µ–¥—ñ–∞–Ω–∞–º–∏ –¥–ª—è –∑–∞–∑–Ω–∞—á–µ–Ω–∏—Ö –Ω–∞–ø—Ä—è–º—ñ–≤
        """
        print("\nüìä –ü–∞—Ä—Å–∏–Ω–≥ –≤–∫–ª–∞–¥–∫–∏ '–ú–∞–¥—ñ–∞–Ω–∏'...")

        if '–ú–∞–¥—ñ–∞–Ω–∏' not in self.sheets:
            print("  ‚ö† –í–∫–ª–∞–¥–∫–∞ '–ú–∞–¥—ñ–∞–Ω–∏' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞")
            return None

        df = self.sheets['–ú–∞–¥—ñ–∞–Ω–∏'].copy()

        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ª–∏—à–µ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –Ω–∞–ø—Ä—è–º–∏
        if '–ù–∞–ø—Ä—è–º' in df.columns:
            df = df[df['–ù–∞–ø—Ä—è–º'].isin(directions)]
            print(f"  ‚úì –í—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(df)} –º–µ–¥—ñ–∞–Ω –¥–ª—è –Ω–∞–ø—Ä—è–º—ñ–≤: {', '.join(directions)}")
        else:
            print(f"  ‚ö† –ö–æ–ª–æ–Ω–∫–∞ '–ù–∞–ø—Ä—è–º' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞, –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –≤—Å—ñ {len(df)} –∑–∞–ø–∏—Å—ñ–≤")

        return df

    def validate_methodology(self, indicator_columns: Dict[str, int], dovidnyky_df: pd.DataFrame, results_df: pd.DataFrame) -> Dict:
        """
        –í–∞–ª—ñ–¥–∞—Ü—ñ—è –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç—ñ –¥–∞–Ω–∏—Ö –º–µ—Ç–æ–¥–∏—Ü—ñ –∞—Ç–µ—Å—Ç–∞—Ü—ñ—ó

        Args:
            indicator_columns: –°–ª–æ–≤–Ω–∏–∫ –∑ —ñ–Ω–¥–µ–∫—Å–∞–º–∏ –∫–æ–ª–æ–Ω–æ–∫ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤
            dovidnyky_df: DataFrame –∑ –ø–æ–∫–∞–∑–Ω–∏–∫–∞–º–∏
            results_df: DataFrame –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏

        Returns:
            –°–ª–æ–≤–Ω–∏–∫ –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
        """
        print("\n‚úÖ –í–∞–ª—ñ–¥–∞—Ü—ñ—è –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç—ñ –º–µ—Ç–æ–¥–∏—Ü—ñ –∞—Ç–µ—Å—Ç–∞—Ü—ñ—ó...")

        validation = {
            'total_institutions': len(results_df),
            'total_dovidnyky': len(dovidnyky_df),
            'indicators_found': [],
            'indicators_missing': [],
            'ki_sum_valid': False,
            'formula_valid': False,
            'errors': [],
            'warnings': []
        }

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –≤—Å—ñ—Ö 37 —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤
        found_indicators = set(indicator_columns.keys())
        expected_indicators = set(self.INDICATORS_KI.keys())

        validation['indicators_found'] = sorted(list(found_indicators))
        validation['indicators_missing'] = sorted(list(expected_indicators - found_indicators))

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—É–º–∏ –≤–∞–≥–æ–≤–∏—Ö –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç—ñ–≤
        ki_sum = sum(self.INDICATORS_KI.values())
        if abs(ki_sum - self.TOTAL_KI) < 0.01:
            validation['ki_sum_valid'] = True
            print(f"  ‚úì –°—É–º–∞ –≤–∞–≥–æ–≤–∏—Ö –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç—ñ–≤: {ki_sum:.1f} (–æ—á—ñ–∫—É–≤–∞–ª–æ—Å—å {self.TOTAL_KI})")
        else:
            validation['errors'].append(f"–°—É–º–∞ Ki ({ki_sum:.1f}) –Ω–µ –¥–æ—Ä—ñ–≤–Ω—é—î {self.TOTAL_KI}")

        print(f"  ‚úì –ó–Ω–∞–π–¥–µ–Ω–æ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤: {len(validation['indicators_found'])}/37")

        if validation['indicators_missing']:
            print(f"  ‚ö† –í—ñ–¥—Å—É—Ç–Ω—ñ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏: {', '.join(validation['indicators_missing'])}")
        else:
            print(f"  ‚úÖ –í–°–Ü 37 —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤ –ø—Ä–∏—Å—É—Ç–Ω—ñ –≤ –¥–∞–Ω–∏—Ö!")

        # –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ñ–æ—Ä–º—É–ª–∏ –∞—Ç–µ—Å—Ç–∞—Ü—ñ–π–Ω–æ—ó –æ—Ü—ñ–Ω–∫–∏ –Ω–∞ –≤–∏–ø–∞–¥–∫–æ–≤–∏—Ö –∑—Ä–∞–∑–∫–∞—Ö
        print("\n  üîç –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ñ–æ—Ä–º—É–ª–∏ –∞—Ç–µ—Å—Ç–∞—Ü—ñ—ó –Ω–∞ –∑—Ä–∞–∑–∫–∞—Ö...")
        self._validate_formula_samples(dovidnyky_df, indicator_columns, validation)

        self.validation_results = validation
        return validation

    def _validate_formula_samples(self, dovidnyky_df: pd.DataFrame, indicator_columns: Dict[str, int], validation: Dict):
        """
        –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ñ–æ—Ä–º—É–ª–∏ –ê = (–ö + –ï) √ó –†–ü—ñ √ó –ö–†–Ü –Ω–∞ –≤–∏–ø–∞–¥–∫–æ–≤–∏—Ö –∑—Ä–∞–∑–∫–∞—Ö

        Args:
            dovidnyky_df: DataFrame –∑ –¥–∞–Ω–∏–º–∏
            indicator_columns: –°–ª–æ–≤–Ω–∏–∫ —ñ–Ω–¥–µ–∫—Å—ñ–≤ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä—ñ–≤
            validation: –°–ª–æ–≤–Ω–∏–∫ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –¥–ª—è –¥–æ–¥–∞–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        """
        # –®—É–∫–∞—î–º–æ –∫–æ–ª–æ–Ω–∫–∏ –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        classification_col = None
        expert_col = None
        regional_col = None
        destruction_col = None
        final_col = None

        for col in dovidnyky_df.columns:
            col_str = str(col).lower()
            if '–∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ–π–Ω–∞' in col_str and '–æ—Ü—ñ–Ω–∫–∞' in col_str:
                classification_col = col
            elif '–µ–∫—Å–ø–µ—Ä—Ç–Ω–∞' in col_str and '–æ—Ü—ñ–Ω–∫–∞' in col_str:
                expert_col = col
            elif '—Ä–µ–≥—ñ–æ–Ω–∞–ª—å–Ω–∏–π' in col_str and '–∫–æ—î—Ñ—ñ—Ü' in col_str:
                regional_col = col
            elif '—Ä—É–π–Ω—É–≤–∞–Ω—å' in col_str or '—Ä—É–π–Ω—É–≤–∞–Ω–Ω—è' in col_str:
                destruction_col = col
            elif '–∞—Ç–µ—Å—Ç–∞—Ü—ñ–π–Ω–∞' in col_str and '–æ—Ü—ñ–Ω–∫–∞' in col_str:
                final_col = col

        if all([classification_col, expert_col, regional_col, destruction_col, final_col]):
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ñ–æ—Ä–º—É–ª—É –Ω–∞ –∫—ñ–ª—å–∫–æ—Ö –∑—Ä–∞–∑–∫–∞—Ö
            sample_size = min(5, len(dovidnyky_df))
            matches = 0

            for idx in range(sample_size):
                try:
                    K = pd.to_numeric(dovidnyky_df.iloc[idx][classification_col], errors='coerce')
                    E = pd.to_numeric(dovidnyky_df.iloc[idx][expert_col], errors='coerce')
                    RPI = pd.to_numeric(dovidnyky_df.iloc[idx][regional_col], errors='coerce')
                    KRI = pd.to_numeric(dovidnyky_df.iloc[idx][destruction_col], errors='coerce')
                    A_actual = pd.to_numeric(dovidnyky_df.iloc[idx][final_col], errors='coerce')

                    if pd.notna(K) and pd.notna(E) and pd.notna(RPI) and pd.notna(KRI) and pd.notna(A_actual):
                        A_calculated = (K + E) * RPI * KRI

                        # –î–æ–ø—É—Å–∫–∞—î–º–æ –≤—ñ–¥—Ö–∏–ª–µ–Ω–Ω—è 0.1%
                        if abs(A_calculated - A_actual) / max(A_actual, 0.01) < 0.001:
                            matches += 1
                except (ValueError, TypeError):
                    continue

            if matches >= sample_size * 0.8:  # 80% —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω—å
                validation['formula_valid'] = True
                print(f"    ‚úÖ –§–æ—Ä–º—É–ª–∞ –≤–∞–ª—ñ–¥–Ω–∞: {matches}/{sample_size} –∑—Ä–∞–∑–∫—ñ–≤ —Å–ø—ñ–≤–ø–∞–ª–∏")
            else:
                validation['warnings'].append(f"–§–æ—Ä–º—É–ª–∞ –Ω–µ –≤–∞–ª—ñ–¥—É—î—Ç—å—Å—è: –ª–∏—à–µ {matches}/{sample_size} –∑—Ä–∞–∑–∫—ñ–≤")
                print(f"    ‚ö† –§–æ—Ä–º—É–ª–∞: {matches}/{sample_size} –∑—Ä–∞–∑–∫—ñ–≤ —Å–ø—ñ–≤–ø–∞–ª–∏")
        else:
            validation['warnings'].append("–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤—Å—ñ—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó —Ñ–æ—Ä–º—É–ª–∏")

    def consolidate_data(self, directions=['–°—É—Å–ø—ñ–ª—å–Ω–∏–π', '–ê–≥—Ä–∞—Ä–Ω–æ-–≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–∏–π']) -> Dict:
        """
        –ö–æ–Ω—Å–æ–ª—ñ–¥–∞—Ü—ñ—è –≤—Å—ñ—Ö –¥–∞–Ω–∏—Ö —É —î–¥–∏–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É

        Args:
            directions: –°–ø–∏—Å–æ–∫ –Ω–∞—É–∫–æ–≤–∏—Ö –Ω–∞–ø—Ä—è–º—ñ–≤ –¥–ª—è –æ–±—Ä–æ–±–∫–∏

        Returns:
            –°–ª–æ–≤–Ω–∏–∫ –∑ –∫–æ–Ω—Å–æ–ª—ñ–¥–æ–≤–∞–Ω–∏–º–∏ –¥–∞–Ω–∏–º–∏
        """
        print("\nüîÑ –ö–æ–Ω—Å–æ–ª—ñ–¥–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö...")

        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ –∑ —Ä—ñ–∑–Ω–∏—Ö –∞—Ä–∫—É—à—ñ–≤
        results_df = self.parse_results_sheet(directions)
        detali_df = self.parse_detali_sheet(directions)
        medians_df = self.parse_medians_sheet(directions)
        dynamika_df = self.parse_dynamika_sheet(directions)

        # –§–æ—Ä–º—É—î–º–æ –∫–æ–Ω—Å–æ–ª—ñ–¥–æ–≤–∞–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        self.consolidated_data = {
            'results': results_df,
            'detali': detali_df,
            'medians': medians_df,
            'dynamika': dynamika_df
        }

        print(f"  ‚úì –ö–æ–Ω—Å–æ–ª—ñ–¥–æ–≤–∞–Ω–æ:")
        print(f"    - –†–µ–∑—É–ª—å—Ç–∞—Ç–∏: {len(results_df)} —É—Å—Ç–∞–Ω–æ–≤")
        if detali_df is not None:
            print(f"    - –î–µ—Ç–∞–ª—ñ: {len(detali_df)} –¥–µ—Ç–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö –∑–∞–ø–∏—Å—ñ–≤")
        if medians_df is not None:
            print(f"    - –ú–µ–¥—ñ–∞–Ω–∏: {len(medians_df)} –∑–Ω–∞—á–µ–Ω—å –º–µ–¥—ñ–∞–Ω")
        if dynamika_df is not None:
            print(f"    - –î–∏–Ω–∞–º—ñ–∫–∞: {len(dynamika_df)} —á–∞—Å–æ–≤–∏—Ö –∑–∞–ø–∏—Å—ñ–≤")

        return self.consolidated_data

    def export_to_csv(self, output_dir: str):
        """
        –ï–∫—Å–ø–æ—Ä—Ç –∫–æ–Ω—Å–æ–ª—ñ–¥–æ–≤–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É CSV —Ñ–∞–π–ª–∏

        Args:
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è CSV —Ñ–∞–π–ª—ñ–≤
        """
        if self.consolidated_data is None:
            raise ValueError("–°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ –∫–æ–Ω—Å–æ–ª—ñ–¥–∞—Ü—ñ—é –¥–∞–Ω–∏—Ö")

        print(f"\nüíæ –ï–∫—Å–ø–æ—Ä—Ç —É CSV: {output_dir}")

        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        # –ï–∫—Å–ø–æ—Ä—Ç—É—î–º–æ –∫–æ–∂–µ–Ω DataFrame –æ–∫—Ä–µ–º–æ
        for name, df in self.consolidated_data.items():
            if df is not None and len(df) > 0:
                output_path = output_dir / f"{name}.csv"
                df.to_csv(output_path, index=False, encoding='utf-8-sig')
                print(f"  ‚úì {name}.csv: {len(df)} –∑–∞–ø–∏—Å—ñ–≤")

    def export_to_json(self, output_dir: str):
        """
        –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è JSON —Ñ–∞–π–ª—ñ–≤ –¥–ª—è –≤–µ–±-–≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞

        Args:
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è JSON —Ñ–∞–π–ª—ñ–≤
        """
        print(f"\nüì¶ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è JSON —Ñ–∞–π–ª—ñ–≤ —É {output_dir}")

        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        if self.consolidated_data is None:
            raise ValueError("–°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–æ–Ω–∞–π—Ç–µ –∫–æ–Ω—Å–æ–ª—ñ–¥–∞—Ü—ñ—é –¥–∞–Ω–∏—Ö")

        # 1. –ú–µ—Ç–∞–¥–∞–Ω—ñ –º–µ—Ç–æ–¥–∏–∫–∏
        methodology = {
            'total_ki': self.TOTAL_KI,
            'indicators': self.INDICATORS_KI,
            'blocks': self.INDICATOR_BLOCKS,
            'science_directions': self.SCIENCE_DIRECTIONS,
            'attestation_groups': self.ATTESTATION_GROUPS,
            'indicators_count': len(self.INDICATORS_KI),
            'blocks_count': len(self.INDICATOR_BLOCKS)
        }

        with open(output_dir / 'methodology.json', 'w', encoding='utf-8') as f:
            json.dump(methodology, f, ensure_ascii=False, indent=2)
        print("  ‚úì methodology.json")

        # 2. –û—Å–Ω–æ–≤–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∞—Ç–µ—Å—Ç–∞—Ü—ñ—ó (–≤—Å—ñ —É—Å—Ç–∞–Ω–æ–≤–∏)
        results_df = self.consolidated_data['results']
        if results_df is not None and len(results_df) > 0:
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ NaN —É None –¥–ª—è –∫–æ—Ä–µ–∫—Ç–Ω–æ–≥–æ JSON
            results_dict = results_df.replace({np.nan: None}).to_dict('records')

            with open(output_dir / 'all_results.json', 'w', encoding='utf-8') as f:
                json.dump(results_dict, f, ensure_ascii=False, indent=2)
            print(f"  ‚úì all_results.json ({len(results_dict)} —É—Å—Ç–∞–Ω–æ–≤)")

        # 3. –î–µ—Ç–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ –ø–æ —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞—Ö
        detali_df = self.consolidated_data['detali']
        if detali_df is not None and len(detali_df) > 0:
            detali_dict = detali_df.replace({np.nan: None}).to_dict('records')

            with open(output_dir / 'detali.json', 'w', encoding='utf-8') as f:
                json.dump(detali_dict, f, ensure_ascii=False, indent=2)
            print(f"  ‚úì detali.json ({len(detali_dict)} –¥–µ—Ç–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö –∑–∞–ø–∏—Å—ñ–≤)")

        # 4. –ú–µ–¥—ñ–∞–Ω–∏ –ø–æ–∫–∞–∑–Ω–∏–∫—ñ–≤
        medians_df = self.consolidated_data['medians']
        if medians_df is not None and len(medians_df) > 0:
            medians_dict = medians_df.replace({np.nan: None}).to_dict('records')

            with open(output_dir / 'medians.json', 'w', encoding='utf-8') as f:
                json.dump(medians_dict, f, ensure_ascii=False, indent=2)
            print(f"  ‚úì medians.json ({len(medians_dict)} –∑–Ω–∞—á–µ–Ω—å –º–µ–¥—ñ–∞–Ω)")

        # 5. –î–∏–Ω–∞–º—ñ–∫–∞ –ø–æ–∫–∞–∑–Ω–∏–∫—ñ–≤ (—á–∞—Å–æ–≤—ñ —Ä—è–¥–∏)
        dynamika_df = self.consolidated_data['dynamika']
        if dynamika_df is not None and len(dynamika_df) > 0:
            dynamika_dict = dynamika_df.replace({np.nan: None}).to_dict('records')

            with open(output_dir / 'dynamika.json', 'w', encoding='utf-8') as f:
                json.dump(dynamika_dict, f, ensure_ascii=False, indent=2)
            print(f"  ‚úì dynamika.json ({len(dynamika_dict)} —á–∞—Å–æ–≤–∏—Ö –∑–∞–ø–∏—Å—ñ–≤)")

        # 6. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –Ω–∞—É–∫–æ–≤–∏–º –Ω–∞–ø—Ä—è–º–∞–º
        if results_df is not None and len(results_df) > 0 and '–ù–∞–ø—Ä—è–º' in results_df.columns:
            stats_by_direction = {}
            for direction in results_df['–ù–∞–ø—Ä—è–º'].unique():
                direction_data = results_df[results_df['–ù–∞–ø—Ä—è–º'] == direction]

                # –ü—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ —É—Å—Ç–∞–Ω–æ–≤ –∑–∞ –≥—Ä—É–ø–∞–º–∏
                groups_count = {}
                if '–ì—Ä—É–ø–∞' in direction_data.columns:
                    for group in direction_data['–ì—Ä—É–ø–∞'].unique():
                        if pd.notna(group):
                            groups_count[group] = int(direction_data[direction_data['–ì—Ä—É–ø–∞'] == group].shape[0])

                stats_by_direction[direction] = {
                    'total': int(len(direction_data)),
                    'groups': groups_count
                }

            with open(output_dir / 'stats_by_direction.json', 'w', encoding='utf-8') as f:
                json.dump(stats_by_direction, f, ensure_ascii=False, indent=2)
            print("  ‚úì stats_by_direction.json")

        print(f"\n‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è JSON –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {output_dir}")

    def generate_summary_report(self) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø—ñ–¥—Å—É–º–∫–æ–≤–æ–≥–æ –∑–≤—ñ—Ç—É

        Returns:
            –¢–µ–∫—Å—Ç –∑–≤—ñ—Ç—É
        """
        report = []
        report.append("=" * 80)
        report.append("–ü–Ü–î–°–£–ú–ö–û–í–ò–ô –ó–í–Ü–¢ –ü–ê–†–°–ò–ù–ì–£ –î–ê–ù–ò–• –ê–¢–ï–°–¢–ê–¶–Ü–á –ó–í–û")
        report.append("=" * 80)
        report.append("")

        report.append(f"üìÇ –í—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª: {self.excel_path.name}")
        report.append(f"üìä –í–∫–ª–∞–¥–æ–∫ –æ–±—Ä–æ–±–ª–µ–Ω–æ: {len(self.sheets)}")
        report.append("")

        if self.consolidated_data:
            report.append("üìà –ö–û–ù–°–û–õ–Ü–î–û–í–ê–ù–Ü –î–ê–ù–Ü:")
            results_df = self.consolidated_data.get('results')
            if results_df is not None:
                report.append(f"  ‚Ä¢ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏: {len(results_df)} —É—Å—Ç–∞–Ω–æ–≤")

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –Ω–∞–ø—Ä—è–º–∞—Ö
                if '–ù–∞–ø—Ä—è–º' in results_df.columns:
                    report.append("\n  üìä –ó–∞ –Ω–∞—É–∫–æ–≤–∏–º–∏ –Ω–∞–ø—Ä—è–º–∞–º–∏:")
                    for direction in sorted(results_df['–ù–∞–ø—Ä—è–º'].unique()):
                        count = len(results_df[results_df['–ù–∞–ø—Ä—è–º'] == direction])
                        report.append(f"    - {direction}: {count} —É—Å—Ç–∞–Ω–æ–≤")

                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥—Ä—É–ø–∞—Ö
                        if '–ì—Ä—É–ø–∞' in results_df.columns:
                            direction_data = results_df[results_df['–ù–∞–ø—Ä—è–º'] == direction]
                            for group in sorted(direction_data['–ì—Ä—É–ø–∞'].dropna().unique()):
                                group_count = len(direction_data[direction_data['–ì—Ä—É–ø–∞'] == group])
                                report.append(f"      ‚Ä¢ –ì—Ä—É–ø–∞ {group}: {group_count} —É—Å—Ç–∞–Ω–æ–≤")

            detali_df = self.consolidated_data.get('detali')
            if detali_df is not None:
                report.append(f"\n  ‚Ä¢ –î–µ—Ç–∞–ª—ñ: {len(detali_df)} –¥–µ—Ç–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö –∑–∞–ø–∏—Å—ñ–≤")

            medians_df = self.consolidated_data.get('medians')
            if medians_df is not None:
                report.append(f"  ‚Ä¢ –ú–µ–¥—ñ–∞–Ω–∏: {len(medians_df)} –∑–Ω–∞—á–µ–Ω—å")

            dynamika_df = self.consolidated_data.get('dynamika')
            if dynamika_df is not None:
                report.append(f"  ‚Ä¢ –î–∏–Ω–∞–º—ñ–∫–∞: {len(dynamika_df)} —á–∞—Å–æ–≤–∏—Ö –∑–∞–ø–∏—Å—ñ–≤")

        report.append("")
        report.append("=" * 80)

        return "\n".join(report)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""

    # –®–ª—è—Ö–∏ –¥–æ —Ñ–∞–π–ª—ñ–≤
    base_dir = Path(__file__).parent.parent
    excel_path = base_dir / "data" / "–û–≥–æ–ª–æ—à–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤.xlsx"
    csv_output_dir = base_dir / "data" / "csv"
    json_output_dir = base_dir / "data" / "json"

    # –ù–∞–ø—Ä—è–º–∏ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ (–ª–∏—à–µ –°—É—Å–ø—ñ–ª—å–Ω–∏–π —Ç–∞ –ê–≥—Ä–∞—Ä–Ω–æ-–≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–∏–π)
    directions = ['–°—É—Å–ø—ñ–ª—å–Ω–∏–π', '–ê–≥—Ä–∞—Ä–Ω–æ-–≤–µ—Ç–µ—Ä–∏–Ω–∞—Ä–Ω–∏–π']

    print("üöÄ –ü–û–ß–ê–¢–û–ö –ü–ê–†–°–ò–ù–ì–£ –î–ê–ù–ò–• –ê–¢–ï–°–¢–ê–¶–Ü–á –ó–í–û")
    print("=" * 80)
    print(f"üìå –û–±—Ä–æ–±–∫–∞ –Ω–∞–ø—Ä—è–º—ñ–≤: {', '.join(directions)}")
    print("=" * 80)

    try:
        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –ø–∞—Ä—Å–µ—Ä–∞
        parser = AttestationDataParser(str(excel_path))

        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤—Å—ñ—Ö –≤–∫–ª–∞–¥–æ–∫
        parser.load_all_sheets()

        # –ö–æ–Ω—Å–æ–ª—ñ–¥–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö –¥–ª—è –∑–∞–∑–Ω–∞—á–µ–Ω–∏—Ö –Ω–∞–ø—Ä—è–º—ñ–≤
        parser.consolidate_data(directions)

        # –ï–∫—Å–ø–æ—Ä—Ç —É CSV
        parser.export_to_csv(str(csv_output_dir))

        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è JSON —Ñ–∞–π–ª—ñ–≤
        parser.export_to_json(str(json_output_dir))

        # –ü—ñ–¥—Å—É–º–∫–æ–≤–∏–π –∑–≤—ñ—Ç
        print("\n" + parser.generate_summary_report())

        print("\n‚úÖ –ü–ê–†–°–ò–ù–ì –£–°–ü–Ü–®–ù–û –ó–ê–í–ï–†–®–ï–ù–û!")

    except Exception as e:
        print(f"\n‚ùå –ü–û–ú–ò–õ–ö–ê: {str(e)}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()
